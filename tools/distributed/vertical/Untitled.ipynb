{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d60c2c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import onnx\n",
    "from onnx import helper, checker\n",
    "import re\n",
    "import argparse\n",
    "import json,copy\n",
    "import numpy as np\n",
    "from data_json import *\n",
    "from onnx_split import *\n",
    "from CodeGen import *\n",
    "\n",
    "\n",
    "def onnx_ncnn(origin_model, mapping_file, platform_file):\n",
    "\n",
    "    with open(platform_file, 'r') as f:\n",
    "            platform = f.readlines()\n",
    "            #print (platform)\n",
    "            for i in range(len(platform)):\n",
    "                temp = platform[i].split(':')[0]\n",
    "                platform[i] = temp.replace('\\n','')\n",
    "    #print (platform)\n",
    "    platform_num = len(platform)\n",
    "    \n",
    "    platform_dict={}\n",
    "    ######platform 对应id\n",
    "    for i in range(platform_num):\n",
    "        platform_dict[platform[i]] = i\n",
    "    \n",
    "    print (\"platform dict: \", platform_dict)\n",
    "    \n",
    "    platform_mapping = load_json(mapping_file)\n",
    "    engine_num = len(list(platform_mapping))\n",
    "    input_tensor_dict = {}\n",
    "    for key, value in platform_mapping.items():    \n",
    "        onnx_extract(origin_model, './models/'+key+'.onnx', value)\n",
    "        input_tensor_dict[key] =  getInputlayers('./models/'+key+'.onnx')\n",
    "    input_tensors_jsonFile = open('./models/input_tensors_list.json', \"w\")\n",
    "    input_tensors_content = json.dumps(input_tensor_dict)\n",
    "    input_tensors_jsonFile.write(input_tensors_content)\n",
    "    input_tensors_jsonFile.close()\n",
    "    input_tensor_dict = load_json('./models/input_tensors_list.json')\n",
    "    output_tensor_dict = {}\n",
    "    \n",
    "    platform_list = list(platform_dict)\n",
    "    \n",
    "    \n",
    "    #对于每个engine的node\n",
    "    for i in range(engine_num):\n",
    "        platform_name = platform_list[i]\n",
    "        output_list = []\n",
    "        computing_nodes = list(platform_mapping[platform_name])\n",
    "        for node in computing_nodes:\n",
    "            for key, value in input_tensor_dict.items():\n",
    "                if key==platform_name:\n",
    "                    continue\n",
    "                if node in value:\n",
    "                    if node not in output_list:\n",
    "                        output_list.append(node)\n",
    "    \n",
    "        output_tensor_dict[platform_name] = output_list\n",
    "    \n",
    "    print (output_tensor_dict)\n",
    "    output_tensors_jsonFile = open('./models/output_tensors_list.json', \"w\")\n",
    "    output_tensors_content = json.dumps(output_tensor_dict)\n",
    "    output_tensors_jsonFile.write(output_tensors_content)\n",
    "    output_tensors_jsonFile.close()\n",
    "    \n",
    "    send_jsonFile = open('./models/sender.json', \"w\")\n",
    "    recv_jsonFile = open('./models/receiver.json', \"w\")\n",
    "    \n",
    "    \n",
    "    receiver_dict_list = {}\n",
    "    sender_dict_list = {}\n",
    "    \n",
    "    tag_dict_list = {}\n",
    "    tag = 0\n",
    "    send_len = 0\n",
    "    \n",
    "    for key, value in platform_mapping.items():\n",
    "        receiver_dict = {}\n",
    "        sender_dict ={}\n",
    "        tag_dict= {}\n",
    "        input_tensor = input_tensor_dict[key]\n",
    "        for k, v in input_tensor_dict.items():\n",
    "            if k == key:\n",
    "                continue\n",
    "            for per_input_tensor in v:\n",
    "                if per_input_tensor in value:\n",
    "                    if per_input_tensor in sender_dict:\n",
    "                        sender_dict[per_input_tensor].append(k)\n",
    "                        tag_dict[k] = tag\n",
    "                        tag+=1\n",
    "                        send_len +=1\n",
    "                    else:\n",
    "                        sender_dict[per_input_tensor] = [k]\n",
    "                        tag_dict[k] = tag\n",
    "                        tag+=1\n",
    "                        send_len +=1\n",
    "    \n",
    "        sender_dict_list[key] = sender_dict\n",
    "        tag_dict_list[key] = tag_dict\n",
    "    \n",
    "    \n",
    "    \n",
    "        for per_tensor in input_tensor:\n",
    "    ###--------------------------------\n",
    "            find = None\n",
    "            for search_key, search_value in platform_mapping.items():\n",
    "                if per_tensor in search_value:\n",
    "                    find = search_key\n",
    "                    break\n",
    "            if find:\n",
    "                if per_tensor in sender_dict:\n",
    "                    receiver_dict[per_tensor].append(find)\n",
    "                else:\n",
    "                    receiver_dict[per_tensor] = [find]\n",
    "        receiver_dict_list[key] = receiver_dict\n",
    "        #print (key, \"receiver:  \",receiver_dict)\n",
    "    \n",
    "    receiver_dict_content = json.dumps(receiver_dict_list)\n",
    "    recv_jsonFile.write(receiver_dict_content)\n",
    "    \n",
    "    sender_dict_content = json.dumps(sender_dict_list)\n",
    "    send_jsonFile.write(sender_dict_content)\n",
    "    \n",
    "    send_jsonFile.close()\n",
    "    recv_jsonFile.close()\n",
    "    \n",
    "    origin_input_tensor = getInputlayers(origin_model)\n",
    "    origin_output_tensor = []\n",
    "    for i in load_onnx(origin_model).output:\n",
    "        origin_output_tensor.append(i.name)\n",
    "    print (\"orgin input tensors: *** :\",origin_input_tensor)\n",
    "    print (\"origin output tensors: ^^^ :\", origin_output_tensor)\n",
    "    \n",
    "    for i in range(engine_num):\n",
    "        platform_name = platform_list[i]\n",
    "        computing_nodes = list(platform_mapping[platform_name])\n",
    "        sender_list = list(sender_dict_list[platform_name])\n",
    "    \n",
    "        model = onnx.load('./models/'+platform_name+'.onnx')\n",
    "        model = onnx.shape_inference.infer_shapes(model)\n",
    "        graph = model.graph\n",
    "    \n",
    "        #print(\"Check input model Errors: \", onnx.checker.check_model(model))\n",
    "        #Generate a name for all node if they have none.\n",
    "        nodeIdx = 0;\n",
    "        for n in graph.node:\n",
    "            if n.name == '':\n",
    "                n.name = str(n.output[0])\n",
    "    \n",
    "        input_map = generate_node_dict(graph.input)\n",
    "        output_map = generate_node_dict(graph.output)\n",
    "        initializer_map = generate_node_dict(graph.initializer)\n",
    "        value_map = generate_node_dict(graph.value_info)\n",
    "        node_map = generate_node_dict(graph.node)\n",
    "    \n",
    "    \n",
    "        for j in graph.output:\n",
    "            sender_list.append(j.name)\n",
    "        order_sender_list = [n for n in list(node_map.keys()) if n in sender_list]\n",
    "        #print (platform_mapping[platform[i]])\n",
    "    \n",
    "        for j in order_sender_list:\n",
    "            engine_name = str(platform[i]) + str(j) +'.onnx'\n",
    "            node_input_names = []\n",
    "            node_input_names =  traceUpNodes(graph, j,node_input_names, node_map, 0, initializer_map)\n",
    "            onnx_extract('./models/'+str(platform[i])+'.onnx', './models/'+engine_name, node_input_names)\n",
    "    \n",
    "    \n",
    "    # output_names_list = []\n",
    "    # for i in graph.node:\n",
    "    #     output_names_list.append(i.output[0])\n",
    "    # print (output_names_list)\n",
    "    ##############\n",
    "    #-------------\n",
    "    ##############\n",
    "    cpp = CppFile(\"./models/multinode.cpp\")\n",
    "    \n",
    "    \n",
    "    cpp(\"#include \\\"net.h\\\"\")\n",
    "    \n",
    "    cpp(\"#include <algorithm>\")\n",
    "    cpp(\"#include <opencv2/core/core.hpp>\")\n",
    "    cpp(\"#include <opencv2/highgui/highgui.hpp>\")\n",
    "    cpp(\"#include <opencv2/opencv.hpp>\")\n",
    "    cpp(\"#include <opencv2/core.hpp>\")\n",
    "    cpp(\"#include <opencv2/imgproc.hpp>\")\n",
    "    cpp(\"#include <opencv2/highgui.hpp>\")\n",
    "    cpp(\"#include <opencv2/videoio.hpp>\")\n",
    "    \n",
    "\n",
    "    cpp(\"#include <stdio.h>\")\n",
    "    cpp(\"#include <vector>\")\n",
    "    cpp(\"#include <mpi.h>\\n\")\n",
    "    \n",
    "\n",
    "    cpp(\"static int load_labels(std::string path, std::vector<std::string>& labels)\")\n",
    "    cpp(\"{    \")\n",
    "    cpp(\"    FILE* fp = fopen(path.c_str(), \\\"r\\\");\")\n",
    "    cpp(\"     \")\n",
    "    cpp(\"    while (!feof(fp))\")\n",
    "    cpp(\"    {\")\n",
    "    cpp(\"        char str[1024];\")\n",
    "    cpp(\"        fgets(str, 1024, fp);  \")\n",
    "    cpp(\"        std::string str_s(str);\")\n",
    "    cpp(\"     \")\n",
    "    cpp(\"        if (str_s.length() > 0)\")\n",
    "    cpp(\"        {\")\n",
    "    cpp(\"            for (int i = 0; i < str_s.length(); i++)\")\n",
    "    cpp(\"            {\")\n",
    "    cpp(\"                if (str_s[i] == ' ')\")\n",
    "    cpp(\"                {\")\n",
    "    cpp(\"                    std::string strr = str_s.substr(i, str_s.length() - i - 1);\")\n",
    "    cpp(\"                    labels.push_back(strr);\")\n",
    "    cpp(\"                    i = str_s.length();\")\n",
    "    cpp(\"                }\")\n",
    "    cpp(\"            }\")\n",
    "    cpp(\"        }\")\n",
    "    cpp(\"    }\")\n",
    "    cpp(\"    return 0;\")\n",
    "    cpp(\"}    \")\n",
    "\n",
    "\n",
    "\n",
    "    cpp(\"//static int print_topk(const std::vector<float>& cls_scores, int topk)\")\n",
    "    cpp(\"static int print_topk(const std::vector<float>& cls_scores, int topk, std::vector<int>& index_result, std::vector<float>& score_result)\")\n",
    "    cpp(\"{   \")\n",
    "    cpp(\"    // partial sort topk with index\")\n",
    "    cpp(\"    int size = cls_scores.size();\")\n",
    "    cpp(\"    std::vector<std::pair<float, int> > vec;\")\n",
    "    cpp(\"    vec.resize(size); \")\n",
    "    cpp(\"    for (int i = 0; i < size; i++)\")\n",
    "    cpp(\"    {   \")\n",
    "    cpp(\"        vec[i] = std::make_pair(cls_scores[i], i);\")\n",
    "    cpp(\"    }\\n\")\n",
    "    \n",
    "    cpp(\"    std::partial_sort(vec.begin(), vec.begin() + topk, vec.end(),\")\n",
    "    cpp(\"                      std::greater<std::pair<float, int> >());\\n\")\n",
    "    \n",
    "    cpp(\"    // print topk and score\")\n",
    "    cpp(\"    for (int i = 0; i < topk; i++)\")\n",
    "    cpp(\"    {   \")\n",
    "    cpp(\"        float score = vec[i].first;\")\n",
    "    cpp(\"        int index = vec[i].second;\")\n",
    "    cpp(\"        fprintf(stderr, \\\"%d = %f\\\\n\\\", index, score);\")\n",
    "    cpp(\"        index_result.push_back(index);\")\n",
    "    cpp(\"        score_result.push_back(score);\")\n",
    "    cpp(\"    }\\n\")\n",
    "    \n",
    "    cpp(\"    return 0;\")\n",
    "    cpp(\"}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    cpp(\"static int multi_classify(const cv::Mat& bgr, std::vector<float>& cls_scores)\")\n",
    "    cpp(\"{\")\n",
    "    \n",
    "    #getInputlayers(input_model)\n",
    "    recv_node_list = []\n",
    "    for k, v in receiver_dict_list.items():\n",
    "        for key, value in v.items():\n",
    "            recv_node_list.append(key)\n",
    "    print (recv_node_list)\n",
    "    request_len = len(recv_node_list) * 2\n",
    "    ### recv + send = len\n",
    "    cpp(\"int irank = MPI::COMM_WORLD.Get_rank();\")\n",
    "    cpp(\"MPI_Request requests[\"+str(send_len*2)+\"];\")\n",
    "    cpp(\"MPI_Status status[\"+str(send_len*2)+\"];\\n\")\n",
    "    \n",
    "    recv_request_index = 0\n",
    "    send_request_index = len(recv_node_list)\n",
    "    \n",
    "    recv_request_dict={}\n",
    "    send_request_dict={}\n",
    "    \n",
    "    #recore request index of mpi communication process\n",
    "    \n",
    "    \n",
    "    for i in range(engine_num):\n",
    "        platform_name = platform_list[i]\n",
    "        computing_nodes = list(platform_mapping[platform_name])\n",
    "        sender_list = list(sender_dict_list[platform_name])\n",
    "        receiver_list = list(receiver_dict_list[platform_name])\n",
    "        tag_dict = tag_dict_list[platform_name]\n",
    "        model = onnx.load('./models/'+platform_name+'.onnx')\n",
    "        model = onnx.shape_inference.infer_shapes(model)\n",
    "        graph = model.graph\n",
    "    \n",
    "        #print(\"Check input model Errors: \", onnx.checker.check_model(model))\n",
    "        #Generate a name for all node if they have none.\n",
    "        nodeIdx = 0;\n",
    "        for n in graph.node:\n",
    "            if n.name == '':\n",
    "                n.name = str(n.output[0])\n",
    "    \n",
    "        input_map = generate_node_dict(graph.input)\n",
    "        output_map = generate_node_dict(graph.output)\n",
    "        initializer_map = generate_node_dict(graph.initializer)\n",
    "        value_map = generate_node_dict(graph.value_info)\n",
    "        node_map = generate_node_dict(graph.node)\n",
    "    \n",
    "        for j in graph.output:\n",
    "            sender_list.append(j.name)\n",
    "        order_sender_list = [n for n in list(node_map.keys()) if n in sender_list]\n",
    "    \n",
    "        net_name = \"resnet\" + str(i)\n",
    "        cpp(\"if(irank==\"+str(i)+\"){\")\n",
    "    \n",
    "        for j in receiver_list:\n",
    "            # MPI_Irecv(void *buf, int count, MPI_Datatype datatype, int source,\n",
    "            #      int tag, MPI_Comm comm, MPI_Request * request)\n",
    "            jj_shape = get_node_output_shape(value_map[j])\n",
    "            new_shape = jj_shape[0:1] + jj_shape[2:4] + jj_shape[1:2]\n",
    "    #         new_shape = jj_shape\n",
    "            j_shape = str(new_shape[1:]).replace('[','(').replace(']',')')\n",
    "            j_size = str(j)+\".total()\"\n",
    "    \n",
    "            cpp(\"    ncnn::Mat \"+ str(j)+ j_shape+\";\\n\")\n",
    "            #sender_dict_list[platform_name][j]:\n",
    "            #receiver_dict_list[platform_name][j][0]\n",
    "    #         print (\"tag: \",tag_index)\n",
    "            recv_source = receiver_dict_list[platform_name][j][0]\n",
    "            tag_index = tag_dict_list[recv_source][platform_name]\n",
    "    \n",
    "            cpp(\"    MPI_Irecv((float* )\"+ str(j)+ \", \" +j_size+\n",
    "                \", MPI_FLOAT, \"+str(platform_dict[recv_source])+\", \")\n",
    "            cpp(\"        \"+str(tag_index)+\", MPI_COMM_WORLD, &requests[\" + str(tag_index+ send_len) +\"]);\\n\")\n",
    "            recv_request_dict[j] = recv_request_index\n",
    "            recv_request_index+=1\n",
    "    \n",
    "        for j in order_sender_list:\n",
    "            engine_name = platform[i] + j +'.onnx'\n",
    "            net_name = platform[i] + j\n",
    "            cpp(\"    ncnn::Net \"+ net_name + \";\")\n",
    "    \n",
    "            cpp(\"    \"+net_name+\".load_param(\\\"\"+net_name+\".param\\\");\")\n",
    "            cpp(\"    \"+net_name+\".load_model(\\\"\"+net_name+\".bin\\\");\\n\")\n",
    "    \n",
    "    \n",
    "            input_list = getInputlayers('./models/'+platform[i]+j+'.onnx')\n",
    "            for per_input in input_list:\n",
    "                if (per_input in origin_input_tensor):\n",
    "                    cpp(\"    ncnn::Mat in = ncnn::Mat::from_pixels_resize(bgr.data, ncnn::Mat::PIXEL_BGR, bgr.cols, bgr.rows, 224, 224);\")\n",
    "                    cpp(\"    const float mean_vals[3] = {104.f, 117.f, 123.f};\")\n",
    "                    cpp(\"    in.substract_mean_normalize(mean_vals, 0);\")\n",
    "                else:\n",
    "                    recv_source = receiver_dict_list[platform_name][per_input][0]\n",
    "                    tag_index = tag_dict_list[recv_source][platform_name] + send_len\n",
    "#                    cpp(\"    ncnn::Mat in = ncnn::Mat::from_pixels_resize(bgr.data, ncnn::Mat::PIXEL_BGR, bgr.cols, bgr.rows, 224, 224);\")\n",
    "#                    cpp(\"    const float mean_vals[3] = {127.5f, 127.5f, 127.5f};\")\n",
    "#                    cpp(\"    const float norm_vals[3] = {1.0 / 127.5, 1.0 / 127.5, 1.0 / 127.5};\")\n",
    "#                    cpp(\"    in.substract_mean_normalize(mean_vals, norm_vals);\\n\")\n",
    "            cpp(\"    ncnn::Mat \"+str(j)+\";\\n\")\n",
    "    #             int MPI_Isend(const void *buf, int count, MPI_Datatype datatype, int dest, int tag,\n",
    "    #               MPI_Comm comm, MPI_Request *request)\n",
    "            ### comm tag problem\n",
    "    \n",
    "        cpp(\" }\\n\")\n",
    "\n",
    "###########################################\n",
    "\n",
    "    for i in range(engine_num):\n",
    "        platform_name = platform_list[i]\n",
    "        computing_nodes = list(platform_mapping[platform_name])\n",
    "        sender_list = list(sender_dict_list[platform_name])\n",
    "        receiver_list = list(receiver_dict_list[platform_name])\n",
    "        tag_dict = tag_dict_list[platform_name]\n",
    "        model = onnx.load('./models/'+platform_name+'.onnx')\n",
    "        model = onnx.shape_inference.infer_shapes(model)\n",
    "        graph = model.graph\n",
    "    \n",
    "        #print(\"Check input model Errors: \", onnx.checker.check_model(model))\n",
    "        #Generate a name for all node if they have none.\n",
    "        nodeIdx = 0;\n",
    "        for n in graph.node:\n",
    "            if n.name == '':\n",
    "                n.name = str(n.output[0])\n",
    "    \n",
    "        input_map = generate_node_dict(graph.input)\n",
    "        output_map = generate_node_dict(graph.output)\n",
    "        initializer_map = generate_node_dict(graph.initializer)\n",
    "        value_map = generate_node_dict(graph.value_info)\n",
    "        node_map = generate_node_dict(graph.node)\n",
    "    \n",
    "        for j in graph.output:\n",
    "            sender_list.append(j.name)\n",
    "        order_sender_list = [n for n in list(node_map.keys()) if n in sender_list]\n",
    "    \n",
    "        net_name = \"resnet\" + str(i)\n",
    "        cpp(\"if(irank==\"+str(i)+\"){\")\n",
    "    \n",
    "        for j in receiver_list:\n",
    "            # MPI_Irecv(void *buf, int count, MPI_Datatype datatype, int source,\n",
    "            #      int tag, MPI_Comm comm, MPI_Request * request)\n",
    "            jj_shape = get_node_output_shape(value_map[j])\n",
    "            new_shape = jj_shape[0:1] + jj_shape[2:4] + jj_shape[1:2]\n",
    "    #         new_shape = jj_shape\n",
    "            j_shape = str(new_shape[1:]).replace('[','(').replace(']',')')\n",
    "            j_size = str(j)+\".total()\"\n",
    "    \n",
    "            cpp(\"    ncnn::Mat \"+ str(j)+ j_shape+\";\\n\")\n",
    "            #sender_dict_list[platform_name][j]:\n",
    "            #receiver_dict_list[platform_name][j][0]\n",
    "    #         print (\"tag: \",tag_index)\n",
    "            recv_source = receiver_dict_list[platform_name][j][0]\n",
    "            tag_index = tag_dict_list[recv_source][platform_name]\n",
    "    \n",
    "            cpp(\"    MPI_Irecv((float* )\"+ str(j)+ \", \" +j_size+\n",
    "                \", MPI_FLOAT, \"+str(platform_dict[recv_source])+\", \")\n",
    "            cpp(\"        \"+str(tag_index)+\", MPI_COMM_WORLD, &requests[\" + str(tag_index+ send_len) +\"]);\\n\")\n",
    "            recv_request_dict[j] = recv_request_index\n",
    "            recv_request_index+=1\n",
    "    \n",
    "        for j in order_sender_list:\n",
    "            engine_name = platform[i] + j +'.onnx'\n",
    "            net_name = platform[i] + j\n",
    "            cpp(\"    ncnn::Net \"+ net_name + \";\")\n",
    "    \n",
    "            cpp(\"    \"+net_name+\".load_param(\\\"\"+net_name+\".param\\\");\")\n",
    "            cpp(\"    \"+net_name+\".load_model(\\\"\"+net_name+\".bin\\\");\\n\")\n",
    "    \n",
    "    \n",
    "            input_list = getInputlayers('./models/'+platform[i]+j+'.onnx')\n",
    "            for per_input in input_list:\n",
    "                cpp(\"    ncnn::Extractor ex\"+str(j)+\" = \"+str(net_name)+\".create_extractor();\\n\")\n",
    "                if (per_input in origin_input_tensor):\n",
    "                    cpp(\"    ncnn::Mat in = ncnn::Mat::from_pixels_resize(bgr.data, ncnn::Mat::PIXEL_BGR, bgr.cols, bgr.rows, 224, 224);\")\n",
    "                    cpp(\"    const float mean_vals[3] = {104.f, 117.f, 123.f};\")\n",
    "                    cpp(\"    in.substract_mean_normalize(mean_vals, 0);\")\n",
    "                    cpp(\"    ex\"+str(j)+\".input(\\\"\"+str(per_input)+\"\\\", in);\\n\")\n",
    "                else:\n",
    "                    recv_source = receiver_dict_list[platform_name][per_input][0]\n",
    "                    tag_index = tag_dict_list[recv_source][platform_name] + send_len\n",
    "                    cpp(\"    MPI_Wait(&requests[\" +str(tag_index)+\"], &status[\"+str(tag_index)+\"]);\")\n",
    "                    cpp(\"    ex\"+str(j)+\".input(\\\"\"+str(per_input)+\"\\\", \"+str(per_input)+\");\")\n",
    "#                    cpp(\"    ncnn::Mat in = ncnn::Mat::from_pixels_resize(bgr.data, ncnn::Mat::PIXEL_BGR, bgr.cols, bgr.rows, 224, 224);\")\n",
    "#                    cpp(\"    const float mean_vals[3] = {127.5f, 127.5f, 127.5f};\")\n",
    "#                    cpp(\"    const float norm_vals[3] = {1.0 / 127.5, 1.0 / 127.5, 1.0 / 127.5};\")\n",
    "#                    cpp(\"    in.substract_mean_normalize(mean_vals, norm_vals);\\n\")\n",
    "            cpp(\"    ncnn::Mat \"+str(j)+\";\\n\")\n",
    "            cpp(\"    ex\"+str(j)+\".extract(\\\"\"+str(j)+\"\\\", \"+str(j)+\");\")\n",
    "    #             int MPI_Isend(const void *buf, int count, MPI_Datatype datatype, int dest, int tag,\n",
    "    #               MPI_Comm comm, MPI_Request *request)\n",
    "            ### comm tag problem\n",
    "            j_size = str(j)+\".total()\"\n",
    "    \n",
    "            if j in origin_output_tensor:\n",
    "                cpp(\"    cls_scores.resize(\"+str(j)+\".w);\\n\")\n",
    "                cpp(\"    for (int j = 0; j < \"+str(j)+\".w; j++)\")\n",
    "                cpp(\"    {\")\n",
    "                cpp(\"        cls_scores[j] = \"+str(j)+\"[j];\")\n",
    "                cpp(\"    }\\n\")\n",
    "                #cpp(\"    print_topk(cls_scores, 3);\\n\")\n",
    "                cpp(\"    std::vector<std::string> labels;\")\n",
    "                cpp(\"    load_labels(\\\"synset_words.txt\\\", labels);\")\n",
    "                cpp(\"    std::vector<int> index;\")\n",
    "                cpp(\"    std::vector<float> score;\")\n",
    "                cpp(\"    print_topk(cls_scores, 3, index, score);\")\n",
    "                cpp(\"    for (int i = 0; i < index.size(); i++)\")\n",
    "                cpp(\"    {\")\n",
    "                cpp(\"        fprintf(stderr, \\\"%s \\\\n\\\", labels[index[i]].c_str());\")\n",
    "                cpp(\"    }\")\n",
    "            else:\n",
    "                for dest in sender_dict_list[platform_name][j]:\n",
    "                    tag_index = tag_dict[dest]\n",
    "    #                 print (\"tag: \",tag_index)\n",
    "                    cpp(\"    MPI_Isend((float* )\"+ str(j)+ \", \" +j_size+\n",
    "                    \", MPI_FLOAT, \"+str(platform_dict[dest])+\", \")\n",
    "                    cpp(\"        \"+str(tag_index)+\", MPI_COMM_WORLD, &requests[\" + str(tag_index) +\"]);\\n\")\n",
    "                    cpp(\"    MPI_Wait(&requests[\" +str(tag_index)+\"], &status[\"+str(tag_index)+\"]);\")\n",
    "                    send_request_dict[j] = send_request_index\n",
    "                    send_request_index+=1\n",
    "        cpp(\" }\\n\")\n",
    "\n",
    "        ########################\n",
    "\n",
    "    for i in range(engine_num):\n",
    "        platform_name = platform_list[i]\n",
    "        computing_nodes = list(platform_mapping[platform_name])\n",
    "        sender_list = list(sender_dict_list[platform_name])\n",
    "        receiver_list = list(receiver_dict_list[platform_name])\n",
    "        tag_dict = tag_dict_list[platform_name]\n",
    "        model = onnx.load('./models/'+platform_name+'.onnx')\n",
    "        model = onnx.shape_inference.infer_shapes(model)\n",
    "        graph = model.graph\n",
    "    \n",
    "        #print(\"Check input model Errors: \", onnx.checker.check_model(model))\n",
    "        #Generate a name for all node if they have none.\n",
    "        nodeIdx = 0;\n",
    "        for n in graph.node:\n",
    "            if n.name == '':\n",
    "                n.name = str(n.output[0])\n",
    "    \n",
    "        input_map = generate_node_dict(graph.input)\n",
    "        output_map = generate_node_dict(graph.output)\n",
    "        initializer_map = generate_node_dict(graph.initializer)\n",
    "        value_map = generate_node_dict(graph.value_info)\n",
    "        node_map = generate_node_dict(graph.node)\n",
    "    \n",
    "        for j in graph.output:\n",
    "            sender_list.append(j.name)\n",
    "        order_sender_list = [n for n in list(node_map.keys()) if n in sender_list]\n",
    "    \n",
    "        net_name = \"resnet\" + str(i)\n",
    "        cpp(\"if(irank==\"+str(i)+\"){\")\n",
    "    \n",
    "        for j in receiver_list:\n",
    "            # MPI_Irecv(void *buf, int count, MPI_Datatype datatype, int source,\n",
    "            #      int tag, MPI_Comm comm, MPI_Request * request)\n",
    "            jj_shape = get_node_output_shape(value_map[j])\n",
    "            new_shape = jj_shape[0:1] + jj_shape[2:4] + jj_shape[1:2]\n",
    "    #         new_shape = jj_shape\n",
    "            j_shape = str(new_shape[1:]).replace('[','(').replace(']',')')\n",
    "            j_size = str(j)+\".total()\"\n",
    "    \n",
    "            cpp(\"    ncnn::Mat \"+ str(j)+ j_shape+\";\\n\")\n",
    "            #sender_dict_list[platform_name][j]:\n",
    "            #receiver_dict_list[platform_name][j][0]\n",
    "    #         print (\"tag: \",tag_index)\n",
    "            recv_source = receiver_dict_list[platform_name][j][0]\n",
    "            tag_index = tag_dict_list[recv_source][platform_name]\n",
    "    \n",
    "            cpp(\"    MPI_Irecv((float* )\"+ str(j)+ \", \" +j_size+\n",
    "                \", MPI_FLOAT, \"+str(platform_dict[recv_source])+\", \")\n",
    "            cpp(\"        \"+str(tag_index)+\", MPI_COMM_WORLD, &requests[\" + str(tag_index+ send_len) +\"]);\\n\")\n",
    "            recv_request_dict[j] = recv_request_index\n",
    "            recv_request_index+=1\n",
    "    \n",
    "        for j in order_sender_list:\n",
    "            engine_name = platform[i] + j +'.onnx'\n",
    "            net_name = platform[i] + j\n",
    "            cpp(\"    ncnn::Net \"+ net_name + \";\")\n",
    "    \n",
    "            cpp(\"    \"+net_name+\".load_param(\\\"\"+net_name+\".param\\\");\")\n",
    "            cpp(\"    \"+net_name+\".load_model(\\\"\"+net_name+\".bin\\\");\\n\")\n",
    "    \n",
    "    \n",
    "            input_list = getInputlayers('./models/'+platform[i]+j+'.onnx')\n",
    "            for per_input in input_list:\n",
    "                cpp(\"    ncnn::Extractor ex\"+str(j)+\" = \"+str(net_name)+\".create_extractor();\\n\")\n",
    "                if (per_input in origin_input_tensor):\n",
    "                    cpp(\"    ncnn::Mat in = ncnn::Mat::from_pixels_resize(bgr.data, ncnn::Mat::PIXEL_BGR, bgr.cols, bgr.rows, 224, 224);\")\n",
    "                    cpp(\"    const float mean_vals[3] = {104.f, 117.f, 123.f};\")\n",
    "                    cpp(\"    in.substract_mean_normalize(mean_vals, 0);\")\n",
    "                    cpp(\"    ex\"+str(j)+\".input(\\\"\"+str(per_input)+\"\\\", in);\\n\")\n",
    "                else:\n",
    "                    recv_source = receiver_dict_list[platform_name][per_input][0]\n",
    "                    tag_index = tag_dict_list[recv_source][platform_name] + send_len\n",
    "                    cpp(\"    MPI_Wait(&requests[\" +str(tag_index)+\"], &status[\"+str(tag_index)+\"]);\")\n",
    "                    cpp(\"    ex\"+str(j)+\".input(\\\"\"+str(per_input)+\"\\\", \"+str(per_input)+\");\")\n",
    "#                    cpp(\"    ncnn::Mat in = ncnn::Mat::from_pixels_resize(bgr.data, ncnn::Mat::PIXEL_BGR, bgr.cols, bgr.rows, 224, 224);\")\n",
    "#                    cpp(\"    const float mean_vals[3] = {127.5f, 127.5f, 127.5f};\")\n",
    "#                    cpp(\"    const float norm_vals[3] = {1.0 / 127.5, 1.0 / 127.5, 1.0 / 127.5};\")\n",
    "#                    cpp(\"    in.substract_mean_normalize(mean_vals, norm_vals);\\n\")           \n",
    "            jj_shape = get_node_output_shape(value_map[j])\n",
    "            new_shape = jj_shape[0:1] + jj_shape[2:4] + jj_shape[1:2]\n",
    "    #         new_shape = jj_shape\n",
    "            j_shape = str(new_shape[1:]).replace('[','(').replace(']',')')\n",
    "            j_size = str(j)+\".total()\"\n",
    "            cpp(\"    ncnn::Mat \"+ str(j)+ j_shape+\";\\n\")    \n",
    "            #cpp(\"    ncnn::Mat \"+str(j)+\";\\n\")\n",
    "            cpp(\"    ex\"+str(j)+\".extract(\\\"\"+str(j)+\"\\\", \"+str(j)+\");\")\n",
    "    #             int MPI_Isend(const void *buf, int count, MPI_Datatype datatype, int dest, int tag,\n",
    "    #               MPI_Comm comm, MPI_Request *request)\n",
    "            ### comm tag problem\n",
    "            j_size = str(j)+\".total()\"\n",
    "    \n",
    "            if j in origin_output_tensor:\n",
    "                cpp(\"    cls_scores.resize(\"+str(j)+\".w);\\n\")\n",
    "                cpp(\"    for (int j = 0; j < \"+str(j)+\".w; j++)\")\n",
    "                cpp(\"    {\")\n",
    "                cpp(\"        cls_scores[j] = \"+str(j)+\"[j];\")\n",
    "                cpp(\"    }\\n\")\n",
    "                #cpp(\"    print_topk(cls_scores, 3);\\n\")\n",
    "                cpp(\"    std::vector<std::string> labels;\")\n",
    "                cpp(\"    load_labels(\\\"synset_words.txt\\\", labels);\")\n",
    "                cpp(\"    std::vector<int> index;\")\n",
    "                cpp(\"    std::vector<float> score;\")\n",
    "                cpp(\"    print_topk(cls_scores, 3, index, score);\")\n",
    "                cpp(\"    for (int i = 0; i < index.size(); i++)\")\n",
    "                cpp(\"    {\")\n",
    "                cpp(\"        fprintf(stderr, \\\"%s \\\\n\\\", labels[index[i]].c_str());\")\n",
    "                cpp(\"    }\")\n",
    "            else:\n",
    "                for dest in sender_dict_list[platform_name][j]:\n",
    "                    tag_index = tag_dict[dest]\n",
    "    #                 print (\"tag: \",tag_index)\n",
    "                    cpp(\"    MPI_Isend((float* )\"+ str(j)+ \", \" +j_size+\n",
    "                    \", MPI_FLOAT, \"+str(platform_dict[dest])+\", \")\n",
    "                    cpp(\"        \"+str(tag_index)+\", MPI_COMM_WORLD, &requests[\" + str(tag_index) +\"]);\\n\")\n",
    "                    cpp(\"    MPI_Wait(&requests[\" +str(tag_index)+\"], &status[\"+str(tag_index)+\"]);\")\n",
    "                    send_request_dict[j] = send_request_index\n",
    "                    send_request_index+=1\n",
    "        cpp(\" }\\n\")        \n",
    "\n",
    "    cpp(\"return 0;\\n\")\n",
    "    # cpp(\"MPI_Waitall(\"+str(request_len)+\", requests, status);\\n\")\n",
    "    cpp(\"}\\n\")\n",
    "    cpp(\"int main(int argc, char** argv)\")\n",
    "    cpp(\"{\")\n",
    "    \n",
    "    cpp(\"    MPI::Init(argc, argv);\\n\")\n",
    "    \n",
    "    cpp(\"    // Get the number of processes\")\n",
    "    cpp(\"    int world_size;\")\n",
    "    cpp(\"    world_size = MPI::COMM_WORLD.Get_size();\\n\")\n",
    "    \n",
    "    cpp(\"    // Get the rank of the process\")\n",
    "    cpp(\"    int world_rank;\")\n",
    "    cpp(\"    world_rank = MPI::COMM_WORLD.Get_rank();\\n\")\n",
    "    \n",
    "    \n",
    "    cpp(\"    if (argc != 2)\")\n",
    "    cpp(\"    {\")\n",
    "    cpp(\"        fprintf(stderr, \\\"Usage: %s [imagepath]\\\\n\\\", argv[0]);\")\n",
    "    cpp(\"        return -1;\")\n",
    "    cpp(\"    }\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    cpp(\"    const char* imagepath = argv[1];\\n\")\n",
    "    \n",
    "    cpp(\"    cv::Mat m = cv::imread(imagepath, 1);\")\n",
    "    cpp(\"    if (m.empty())\")\n",
    "    cpp(\"    {\")\n",
    "    cpp(\"        fprintf(stderr, \\\"cv::imread %s failed\\\\n\\\", imagepath);\")\n",
    "    cpp(\"        return -1;\")\n",
    "    cpp(\"    }\\n\")\n",
    "    \n",
    "    cpp(\"    std::vector<float> cls_scores;\")\n",
    "    cpp(\"    multi_classify(m, cls_scores);\\n\")\n",
    "\n",
    "    cpp(\"    // Finalize the MPI environment.\")\n",
    "    cpp(\"    MPI::Finalize();\\n\")\n",
    "    cpp(\"    return 0;\")\n",
    "    cpp(\"}\\n            \")\n",
    "    cpp.close()\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c24de88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_model = 'bvlcalexnet-9.onnx'\n",
    "mapping = './3mapping.json'\n",
    "platform = './platform.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69e311c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platform dict:  {'tx01': 0, 'tx02': 1, 'nx01': 2}\n",
      "Check input model Errors:  None\n",
      "New Output Model ./models/tx01.onnx  Generated. Errors:  None\n",
      "Check input model Errors:  None\n",
      "Check input model Errors:  None\n",
      "New Output Model ./models/tx02.onnx  Generated. Errors:  None\n",
      "Check input model Errors:  None\n",
      "Check input model Errors:  None\n",
      "New Output Model ./models/nx01.onnx  Generated. Errors:  None\n",
      "Check input model Errors:  None\n",
      "{'tx01': ['conv1_2'], 'tx02': ['norm2_1'], 'nx01': ['conv2_2']}\n",
      "Check input model Errors:  None\n",
      "Check input model Errors:  None\n",
      "orgin input tensors: *** : ['data_0']\n",
      "origin output tensors: ^^^ : ['prob_1']\n",
      "Check input model Errors:  None\n",
      "New Output Model ./models/tx01conv1_2.onnx  Generated. Errors:  None\n",
      "Check input model Errors:  None\n",
      "New Output Model ./models/tx02norm2_1.onnx  Generated. Errors:  None\n",
      "Check input model Errors:  None\n",
      "New Output Model ./models/nx01conv2_2.onnx  Generated. Errors:  None\n",
      "Check input model Errors:  None\n",
      "New Output Model ./models/nx01prob_1.onnx  Generated. Errors:  None\n",
      "['conv2_2', 'conv1_2', 'norm2_1']\n",
      "Check input model Errors:  None\n",
      "Check input model Errors:  None\n",
      "Check input model Errors:  None\n",
      "Check input model Errors:  None\n",
      "Check input model Errors:  None\n",
      "Check input model Errors:  None\n",
      "Check input model Errors:  None\n",
      "Check input model Errors:  None\n",
      "Check input model Errors:  None\n",
      "Check input model Errors:  None\n",
      "Check input model Errors:  None\n",
      "Check input model Errors:  None\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'prob_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37168/1668996921.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0monnx_ncnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplatform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_37168/92783429.py\u001b[0m in \u001b[0;36monnx_ncnn\u001b[0;34m(origin_model, mapping_file, platform_file)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;31m#                    cpp(\"    const float norm_vals[3] = {1.0 / 127.5, 1.0 / 127.5, 1.0 / 127.5};\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;31m#                    cpp(\"    in.substract_mean_normalize(mean_vals, norm_vals);\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0mjj_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_node_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m             \u001b[0mnew_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjj_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mjj_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mjj_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;31m#         new_shape = jj_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'prob_1'"
     ]
    }
   ],
   "source": [
    "onnx_ncnn(origin_model, mapping, platform)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
